{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install --upgrade torch --user\n",
    "# !pip3 install torchvision --user\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchLoader(torch.utils.data.Dataset):\n",
    "    def __init__(self, clear_patch, noised_patch):\n",
    "        self.clear_crops = torch.load(clear_patch)\n",
    "        self.noised_crops = torch.load(noised_patch)\n",
    "    def __len__(self):\n",
    "        return len(self.noised_crops)\n",
    "    def __getitem__(self, index):\n",
    "        return self.clear_crops[index], self.noised_crops[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(PatchLoader('../Data/clear_crops.64.train.tensor', \n",
    "                                                           '../Data/noised_crops.64.train.tensor'),\n",
    "                                               batch_size=32, num_workers=16)\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(PatchLoader('../Data/clear_crops.64.val.tensor', \n",
    "                                                         '../Data/noised_crops.64.val.tensor'),\n",
    "                                               batch_size=32, num_workers=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_freer_gpu():\n",
    "    os.system('nvidia-smi -q -d Memory |grep -A4 GPU|grep Free >tmp')\n",
    "    memory_available = [int(x.split()[2]) for x in open('tmp', 'r').readlines()]\n",
    "    return np.argmax(memory_available)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_dist(arr, k):\n",
    "    \"\"\"\n",
    "    arr: torch.Tensor with shape batch x h*w x features\n",
    "    \"\"\"\n",
    "#     arr = arr.view(arr.shape[0], arr.shape[1] * arr.shape[2], -1)\n",
    "    r_arr = torch.sum(arr * arr, dim=2, keepdim=True) # (B,N,1)\n",
    "    mul = torch.matmul(arr, arr.permute(0,2,1))         # (B,M,N)\n",
    "    dist = - (r_arr - 2 * mul + r_arr.permute(0,2,1))       # (B,M,N)\n",
    "    return dist.topk(k=k, dim=-1)[1]\n",
    "\n",
    "\n",
    "def batched_index_select(t, dim, inds):\n",
    "    dummy = inds.unsqueeze(2).expand(inds.size(0), inds.size(1), t.size(2))\n",
    "    out = t.gather(dim, dummy) # b x e x f\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_closest_diff(arr, k):\n",
    "    \"\"\"\n",
    "    arr: torch.Tensor with shape batch x h * w x features\n",
    "    \"\"\"\n",
    "    b, hw, f = arr.shape\n",
    "    dists = pairwise_dist(arr, k)\n",
    "    selected = batched_index_select(arr, 1, dists.view(dists.shape[0], -1)).view(b, hw, k, f)\n",
    "    diff = arr.unsqueeze(2) - selected\n",
    "    return diff\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonLocalAggregation(nn.Module):\n",
    "    def __init__(self, k, input_channels, out_channels, search_area=None):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.diff_fc = nn.Linear(input_channels, out_channels)\n",
    "        self.w_self = nn.Linear(input_channels, out_channels)\n",
    "        self.bias = nn.Parameter(torch.randn(out_channels), requires_grad=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: torch.Tensor with shape batch x features x h x w\n",
    "        \"\"\"\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        b, h, w, f = x.shape\n",
    "        x = x.view(b, h*w, f)\n",
    "        \n",
    "        closest_graph = get_closest_diff(x, self.k)\n",
    "        agg_weights = self.diff_fc(closest_graph) # look closer\n",
    "        agg_self = self.w_self(x)\n",
    "                \n",
    "        x_new = torch.mean(agg_weights, dim=-2) + agg_self + self.bias\n",
    "\n",
    "        return x_new.view(b, h, w, x_new.shape[-1]).permute(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConv(nn.Module):\n",
    "    def __init__(self, k, input_channels, out_channels, search_area=None):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, out_channels, 1)\n",
    "        self.conv2 = nn.Conv2d(input_channels, out_channels, 3, padding=1)\n",
    "        self.NLA = NonLocalAggregation(k, input_channels, out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.mean(torch.stack([self.conv1(x),\n",
    "                                       self.conv2(x),\n",
    "                                       self.NLA(x)]), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessBlock(nn.Module):\n",
    "    def __init__(self, k, kernel_size, input_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(input_channels, out_channels, kernel_size,\n",
    "                              padding=(kernel_size//2, kernel_size//2))\n",
    "        self.activ = nn.LeakyReLU(0.05)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.GC = GraphConv(k, out_channels, out_channels) # out_channels -> out_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.activ(self.conv(x))\n",
    "        x = self.GC(x)\n",
    "        x = self.activ(self.bn(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    def __init__(self, k, input_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.pipeline = nn.Sequential(\n",
    "            GraphConv(k, input_channels, input_channels),\n",
    "            nn.BatchNorm2d(input_channels),\n",
    "            nn.LeakyReLU(0.05),\n",
    "            \n",
    "            GraphConv(k, input_channels, out_channels),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.05),\n",
    "            \n",
    "            GraphConv(k, out_channels, out_channels),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.05),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.pipeline(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_mse = nn.MSELoss()\n",
    "\n",
    "class DNGCNN(nn.Module):\n",
    "    def __init__(self, k, input_channels, hidden_channels, patch_size=(64, 64)):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.preprocessing_blocks = nn.ModuleList([\n",
    "            PreProcessBlock(k, 3, input_channels, hidden_channels),\n",
    "            PreProcessBlock(k, 5, input_channels, hidden_channels),\n",
    "            PreProcessBlock(k, 7, input_channels, hidden_channels),\n",
    "        ])\n",
    "        self.residual_1 = Residual(k, hidden_channels*3, hidden_channels)\n",
    "        self.residual_2 = Residual(k, hidden_channels, hidden_channels)\n",
    "        \n",
    "        self.GC = GraphConv(k, hidden_channels, input_channels)\n",
    "        self.downsample = nn.Sequential(\n",
    "            nn.Conv2d(hidden_channels*3, hidden_channels, 1),\n",
    "            nn.BatchNorm2d(hidden_channels),\n",
    "            nn.LeakyReLU(0.05),\n",
    "            nn.Conv2d(hidden_channels, hidden_channels, 1),\n",
    "            nn.BatchNorm2d(hidden_channels),\n",
    "            nn.LeakyReLU(0.05),\n",
    "        )\n",
    "        \n",
    "    def fit_image(self, image):\n",
    "        processed_image = torch.cat([block(image) for block in self.preprocessing_blocks], dim=1)\n",
    "        residual_1 = self.residual_1(processed_image)\n",
    "        result_1 = residual_1 + self.downsample(processed_image)\n",
    "        residual_2 = self.residual_2(result_1)\n",
    "        result = residual_2 + result_1\n",
    "        return [processed_image, residual_1, result, self.GC(result)]\n",
    "    \n",
    "    def forward(self, clear_image, noised_image):\n",
    "        processed_image, residual_1, residual_2, answer = self.fit_image(clear_image)\n",
    "        n_processed_image, n_residual_1, n_residual_2, n_answer = self.fit_image(noised_image)\n",
    "        perceptual_loss = loss_mse(processed_image, n_processed_image) + \\\n",
    "            loss_mse(residual_1, n_residual_1) + \\\n",
    "            loss_mse(residual_2, n_residual_2)\n",
    "        return n_answer, perceptual_loss\n",
    "    \n",
    "    def forward_eval(self, noised_image):\n",
    "        _, _, _, answer = self.fit_image(noised_image)\n",
    "        return answer\n",
    "\n",
    "    \n",
    "    def forward_image(self, noised_image, device, chunks=16):\n",
    "        p_x, p_y = self.patch_size\n",
    "        splits = torch.split(torch.stack(torch.split(noised_image, p_x)), p_y, dim=2)[:-1]\n",
    "        crops = torch.stack(splits, dim=2)        \n",
    "        crops = crops.view(-1, 1, p_x, p_y)\n",
    "        crops_ = torch.split(crops, crops.shape[0]//chunks, dim=0)\n",
    "        answer = torch.cat([crop + self.forward_eval(crop.cuda(device)).cpu().data for crop in crops_], dim=0)\n",
    "        a_x, a_y = noised_image.shape\n",
    "        return torch.clamp(answer, 0, 1).view(a_x, a_y - a_y%p_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_num = get_freer_gpu()\n",
    "device = torch.device('cuda:{}'.format(gpu_num))\n",
    "\n",
    "device = torch.device('cuda:{}'.format(0))\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNGCNN(8, 1, 32, patch_size=(64, 64)).cuda(device)\n",
    "optim = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_mse = nn.MSELoss()\n",
    "losses = []\n",
    "psnrs = []\n",
    "\n",
    "MODEL_NAME = 'mc11_daq_GCNN_64.valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(im):\n",
    "    if im.max() == 0:\n",
    "        return im\n",
    "    return (im - im.min())/(im.max()-im.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_psnr(image, noised):\n",
    "    return 10 * np.log10(image.max().item()/loss_mse(image, noised).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_diff(real, noised, denoised):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    \n",
    "    for ind, im, noise, denoise in zip(range(1, 13, 3), real[:4], noised[:4], denoised[:4]):\n",
    "        plt.subplot(4, 3, ind)\n",
    "        plt.imshow(im)\n",
    "        plt.yticks([])\n",
    "        plt.xticks([])\n",
    "        plt.title('Clear image')\n",
    "        \n",
    "        plt.subplot(4, 3, ind+1)\n",
    "        plt.imshow(noise)\n",
    "        plt.yticks([])\n",
    "        plt.xticks([])\n",
    "        plt.title('Noised image')\n",
    "        \n",
    "        plt.subplot(4, 3, ind+2)\n",
    "        plt.imshow(denoise)\n",
    "        plt.yticks([])\n",
    "        plt.xticks([])\n",
    "        plt.title('Denoised image')\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "\n",
    "writer = SummaryWriter('./TensorBoard/{}'.format(MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_images_clear =  torch.load('../Data/clear_events_collection_unnormalized_val.tensor')\n",
    "# val_images_noised =  torch.load('../Data/noised_events_collection_unnormalized_val.tensor')\n",
    "\n",
    "val_images_clear =  torch.load('../Data/clear_events_collection_unnormalized_val.tensor')\n",
    "val_images_noised =  torch.load('../Data/noised_events_collection_unnormalized_val.tensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c54a87e2a5e14cdfb8a537b5c84242d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train loop', max=2438, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Test loop', max=157, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train loop', max=2438, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Test loop', max=157, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train loop', max=2438, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Test loop', max=157, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train loop', max=2438, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Test loop', max=157, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train loop', max=2438, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Test loop', max=157, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train loop', max=2438, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Test loop', max=157, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train loop', max=2438, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Test loop', max=157, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train loop', max=2438, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Test loop', max=157, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train loop', max=2438, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Test loop', max=157, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train loop', max=2438, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Test loop', max=157, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train loop', max=2438, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Test loop', max=157, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train loop', max=2438, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Test loop', max=157, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train loop', max=2438, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Test loop', max=157, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train loop', max=2438, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Test loop', max=157, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00247af20a78421dbd340918f412dc55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train loop', max=2438, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in tqdm.tqdm_notebook(range(100)):\n",
    "    for train_ind, (image, noise_image) in enumerate(tqdm.tqdm_notebook(train_dataloader, desc='Train loop', leave=False)):\n",
    "        model.train()\n",
    "        ind = epoch * len(train_dataloader) + train_ind\n",
    "        optim.zero_grad()\n",
    "        image, noise_image = image.cuda(device), noise_image.cuda(device)\n",
    "        denoised_diff, perceptual_loss = model(image, noise_image)\n",
    "        writer.add_scalar('train/perceptual_loss', perceptual_loss.item(), ind)\n",
    "        denoise_image = denoised_diff + noise_image\n",
    "        loss = loss_mse(image, denoise_image)\n",
    "        writer.add_scalar('train/mse_loss', loss.item(), ind)\n",
    "        loss = loss + perceptual_loss\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        writer.add_scalar('train/psnr', compute_psnr(image, denoise_image), ind)\n",
    "\n",
    "    model.eval()\n",
    "    losses, psnrs = [], []\n",
    "    for val_ind, (image, noise_image) in enumerate(tqdm.tqdm_notebook(val_dataloader, desc='Test loop', leave=False)):\n",
    "        image, noise_image = image.cuda(device), noise_image.cuda(device)\n",
    "        denoised_diff, perceptual_loss = model(image, noise_image)\n",
    "        denoise_image = denoised_diff + noise_image\n",
    "        loss = loss_mse(image, denoise_image)\n",
    "        loss = loss + perceptual_loss\n",
    "        losses.append(loss.item())\n",
    "        psnrs.append(compute_psnr(image, denoise_image))\n",
    "    writer.add_scalar('val/psnr', np.mean(psnrs), ind)\n",
    "    writer.add_scalar('val/combined_loss', np.mean(losses), ind)\n",
    "    img_indexes = torch.randint(high=len(noise_image), size=(10,))\n",
    "    dummy_img = torch.cat([image[img_indexes],\n",
    "                           noise_image[img_indexes],\n",
    "                           denoise_image[img_indexes]], dim=0).cpu().data\n",
    "    x = vutils.make_grid(dummy_img, nrow=10)\n",
    "    writer.add_image('val/crops', x, ind)\n",
    "\n",
    "    img_index = torch.randint(high=len(val_images_clear), size=(1,))\n",
    "    clear_image = normalize(val_images_clear[img_index])\n",
    "    noised_image = normalize(val_images_noised[img_index])\n",
    "    denoised_image = normalize(model.forward_image(noised_image.squeeze(0), device).cpu().data.unsqueeze(0))\n",
    "    d_x, d_y = denoised_image.shape[-2:]\n",
    "    writer.add_image('val/clear_image', clear_image[:, :d_x, :d_y], ind)\n",
    "    writer.add_image('val/noised_image', noised_image[:, :d_x, :d_y], ind)\n",
    "    writer.add_image('val/denoised_image', denoised_image[:, :d_x, :d_y], ind)            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'SavedModels/{}.model'.format(MODEL_NAME))\n",
    "torch.save(model.state_dict(), 'SavedModels/{}.state_dict'.format(MODEL_NAME))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
