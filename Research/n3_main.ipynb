{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.utils import _pair\n",
    "\n",
    "import math\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "from time import time\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = utils.AverageMeter(name=\"Loss\")\n",
    "psnr = utils.AverageMeter(name=\"PSNR\")\n",
    "ssim = utils.AverageMeter(name=\"SSIM\")\n",
    "stats = {\"loss\":loss, \"psnr\": psnr, \"ssim\": ssim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Setup:\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        \n",
    "    def create_network(self):\n",
    "        args = self.args\n",
    "        ninchannels=1\n",
    "        noutchannels=1\n",
    "\n",
    "        temp_opt = args.nl_temp\n",
    "\n",
    "        n3block_opt = dict(\n",
    "            k=args.nl_k,\n",
    "            patchsize=args.nl_patchsize,\n",
    "            stride=args.nl_stride,\n",
    "            temp_opt=temp_opt,\n",
    "            embedcnn_opt=args.embedcnn)\n",
    "\n",
    "        dncnn_opt = args.dncnn\n",
    "        dncnn_opt[\"residual\"] = True\n",
    "\n",
    "        net = n3net.N3Net(ninchannels, noutchannels, args.nfeatures_interm,\n",
    "                          nblocks=args.ndncnn, block_opt=dncnn_opt, nl_opt=n3block_opt, residual=False)\n",
    "\n",
    "        return net\n",
    "\n",
    "    def create_test_dataloaders(self):\n",
    "        transform_test = transforms.Compose([\n",
    "            img_dataset.ToGrayscale(),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        testsets = [\n",
    "            (img_dataset.PlainImageFolder(root=denoising_data.set12_val_dir, transform=transform_test, cache=True), \"Set12\"),\n",
    "            (img_dataset.PlainImageFolder(root=denoising_data.bsds500_val68_dir, transform=transform_test, cache=True), \"val68\"),\n",
    "            (img_dataset.PlainImageFolder(root=denoising_data.urban_val_dir, transform=transform_test, cache=True), \"Urban100\")\n",
    "         ]\n",
    "        testloaders = [(torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False, num_workers=1), name)\n",
    "                      for testset,name in testsets]\n",
    "\n",
    "        return testloaders\n",
    "\n",
    "    def create_train_dataloaders(self, patchsize, batchsize, trainsetiters):\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.RandomCrop(patchsize),\n",
    "            preprocess.RandomOrientation90(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            img_dataset.ToGrayscale(),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        self.batchsize=batchsize\n",
    "\n",
    "        train_folders = [\n",
    "            denoising_data.bsds500_train_dir,\n",
    "            denoising_data.bsds500_test_dir\n",
    "        ]\n",
    "\n",
    "        trainset = img_dataset.PlainImageFolder(root=train_folders, transform=transform_train, cache=True)\n",
    "        trainset = torch.utils.data.ConcatDataset([trainset]*trainsetiters)\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchsize,\n",
    "                                                  shuffle=True, num_workers=20)\n",
    "\n",
    "        return trainloader\n",
    "\n",
    "    def data_preprocessing(self, input):\n",
    "        args = self.args\n",
    "        sigma = args.sigma / 255.0\n",
    "        noise = torch.zeros_like(input)\n",
    "        noise.normal_(0, 1)\n",
    "        noise *= sigma\n",
    "        noisy = input + noise\n",
    "        return noisy, input\n",
    "\n",
    "    def create_loss(self):\n",
    "        args = self.args\n",
    "        lossfac = 1600.0 / (args.patchsize**2) # to match loss magnitude of DnCNN training\n",
    "\n",
    "        def criterion(pred, targets):\n",
    "            loss = (0.5*(pred-targets)**2).view(pred.shape[0],-1).sum(dim=1, keepdim=True) * lossfac\n",
    "            return loss\n",
    "\n",
    "        return criterion\n",
    "\n",
    "    def create_optimizer(self):\n",
    "        args = self.args\n",
    "        parameters = utils.parameters_by_module(self.net)\n",
    "        if args.optimizer == \"sgd\":\n",
    "            self.base_lr = args.sgd[\"lr\"]\n",
    "            optimizer =  torch.optim.SGD(parameters, lr=self.base_lr, momentum=args.sgd[\"momentum\"], weight_decay=args.sgd[\"weightdecay\"])\n",
    "        elif args.optimizer == \"adam\":\n",
    "            self.base_lr = args.adam[\"lr\"]\n",
    "            optimizer = torch.optim.Adam(parameters, lr=self.base_lr, weight_decay=args.adam[\"weightdecay\"], betas=(args.adam[\"beta1\"], args.adam[\"beta2\"]), eps=args.adam[\"eps\"])\n",
    "\n",
    "        # bias parameters do not get weight decay\n",
    "        for pg in optimizer.param_groups:\n",
    "            if pg[\"name\"]==\"bias\":\n",
    "                pg[\"weight_decay\"] = 0\n",
    "\n",
    "        return optimizer\n",
    "\n",
    "    def learning_rate_decay(self, epoch):\n",
    "        if epoch > 50:\n",
    "            return 0\n",
    "        decay = 10**(-3.0*epoch/50.0)\n",
    "        return decay\n",
    "\n",
    "    def experiment_dir(self):\n",
    "        if self.args.resume:\n",
    "            self.expname = os.path.split(self.args.resumedir)[-1]\n",
    "            return self.args.resumedir\n",
    "        elif self.args.eval:\n",
    "            self.expname = os.path.split(self.args.evaldir)[-1]\n",
    "            return self.args.evaldir\n",
    "\n",
    "        expname = utils.get_result_dir(self.base_expdir, self.args.suffix)\n",
    "        self.expname = expname\n",
    "        return os.path.join(self.base_expdir, expname)\n",
    "\n",
    "    def get_logdir(self):\n",
    "        expdir = self.expdir\n",
    "        if not self.args.eval:\n",
    "            logdir = \"{}/{}\".format(expdir, \"train\")\n",
    "        else:\n",
    "            i = 0\n",
    "            while True:\n",
    "                logdir = \"{}/{}{:02d}\".format(expdir, \"test\", i)\n",
    "                if not os.path.exists(os.path.join(logdir)):\n",
    "                    break\n",
    "                else:\n",
    "                    i += 1\n",
    "        return logdir\n",
    "\n",
    "\n",
    "    def setup(self):\n",
    "        args = self.args\n",
    "        self.expdir = self.experiment_dir()\n",
    "        self.logdir = self.get_logdir()\n",
    "        self.writer = tbx.SummaryWriter(log_dir=self.logdir)\n",
    "        os.makedirs(self.expdir, exist_ok=True)\n",
    "        os.makedirs(self.logdir, exist_ok=True)\n",
    "\n",
    "        if not args.eval:\n",
    "            utils.save_script_call(os.path.join(self.expdir, \"args.pkl\"), args)\n",
    "        else:\n",
    "            utils.save_script_call(os.path.join(self.logdir, \"args.pkl\"), args)\n",
    "\n",
    "        self.use_cuda = torch.cuda.is_available() and args.use_gpu\n",
    "\n",
    "        self.trainloader = self.create_train_dataloaders(args.patchsize, args.batchsize, args.trainsetiters)\n",
    "        self.net = self.create_network()\n",
    "        self.optimizer = self.create_optimizer()\n",
    "        self.criterion = self.create_loss()\n",
    "\n",
    "        print(self.expname)\n",
    "        print(self.base_expdir)\n",
    "        print(self.net)\n",
    "        nparams = utils.parameter_count(self.net)\n",
    "        print(\"#Parameter {}\".format(nparams))\n",
    "\n",
    "        self.summaries = {}\n",
    "        self.epoch = 0\n",
    "        if args.resume:\n",
    "            self.summaries, self.epoch = utils.load_checkpoint(self.net, self.optimizer, self.expdir, withoptimizer=args.resume_for_train, resume_epoch=args.resumeepoch)\n",
    "\n",
    "        if self.use_cuda:\n",
    "            self.net.cuda()\n",
    "Â© 2019 Git"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
